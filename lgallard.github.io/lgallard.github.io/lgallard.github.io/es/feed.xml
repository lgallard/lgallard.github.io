<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="es"><generator uri="https://jekyllrb.com/" version="3.6.0">Jekyll</generator><link href="https://lgallardo.com/es/feed.xml" rel="self" type="application/atom+xml" /><link href="https://lgallardo.com/es/" rel="alternate" type="text/html" hreflang="es" /><updated>2025-06-09T07:19:12-05:00</updated><id>https://lgallardo.com/es/</id><title type="html">lgallardo.com</title><subtitle>DevOps Engineer and Backend Solutions Developer specializing in Kubernetes, AWS, Python, and Terraform. Sharing insights on cloud infrastructure, automation, and system architecture.</subtitle><author><name>Luis M. Gallardo D.</name></author><entry><title type="html"></title><link href="https://lgallardo.com/es/_i18n/es/2025-06-08-coding-agents-bugbot.md/" rel="alternate" type="text/html" title="" /><published>2025-06-09T07:19:12-05:00</published><updated>2025-06-09T07:19:12-05:00</updated><id>https://lgallardo.com/es/_i18n/es/2025-06-08-coding-agents-bugbot.md</id><content type="html" xml:base="https://lgallardo.com/es/_i18n/es/2025-06-08-coding-agents-bugbot.md/">![BugBot y Copilot: Revisores IA](/assets/images/coding-agents-bugbot-ac817363-8710-4b8f-a6a5-15e47cae8f8c.png){:style=&quot;display:block; margin-left:auto; margin-right:auto; width:60%&quot;}

Recientemente, mientras trabajaba en mis módulos de Terraform, se me ocurrió una idea: **¿Y si uso BugBot para revisar el trabajo de los Coding Agents de Copilot?** Como ya estaba usando Copilot Coding Agents para automatizar PRs y refactorizaciones, decidí probar BugBot como revisor adicional.

## El experimento

Asigné tareas a Copilot Coding Agents para implementar nuevas funcionalidades y correcciones en mis repositorios. Una vez listos los PRs, ejecuté BugBot para revisar los cambios. Los resultados fueron fascinantes:

![PR de Copilot con revisión de BugBot](/assets/images/coding-agents-bugbot-2025-06-09_00-46.png)

BugBot detectó rápidamente problemas que la propia revisión de Copilot no había visto, especialmente en casos límite y uso de variables. Su capacidad de detección de bugs está en otro nivel comparado con las revisiones integradas de Copilot.

![Reporte detallado de BugBot](/assets/images/coding-agents-bugbot-2025-06-09_00-47.png)

Por ejemplo, BugBot señaló una validación regex demasiado restrictiva y variables no utilizadas en un PR generado por Copilot. Proporcionó retroalimentación accionable, que luego trasladé a Copilot para su corrección.

![BugBot y Copilot: Revisores IA](/assets/images/coding-agents-bugbot2025-06-09_00-48.png)

## Puntos destacados

1. **BugBot destaca en la detección de bugs:** Encontró problemas sutiles en los PRs de Copilot Coding Agents, proporcionando explicaciones y sugerencias detalladas.
2. **Copilot Coding Agents destaca en la implementación:** Propone e implementa soluciones rápidamente, y puede interpretar y actuar sobre la retroalimentación de BugBot.
3. **La IA no es infalible:** Incluso usando ambas herramientas, pueden pasar bugs o código desactualizado. Por ejemplo, Copilot generó un workflow usando una GitHub Action obsoleta, y BugBot tampoco lo detectó.

![Error de workflow: Acción de GitHub obsoleta](/assets/images/coding-agents-bugbot-2025-06-09_01-01.png)

## Conclusión

Combinar Copilot Coding Agents y BugBot crea un potente flujo de trabajo de revisión e implementación impulsado por IA. Cada herramienta tiene sus fortalezas: BugBot para la detección profunda de bugs, Copilot para la entrega rápida de soluciones. Sin embargo, la supervisión humana sigue siendo esencial para detectar casos límite y cambios en las plataformas.



&gt; **Nota:** BugBot es un servicio de pago para revisiones automáticas de código. Mis pruebas y experimentos aquí descritos se realizaron durante el periodo de prueba gratuita, lo que me permitió evaluar sus capacidades sin incurrir en costos.

## Referencias

- [GitHub Copilot](https://github.com/features/copilot)
- [Cursor BugBot](https://www.cursor.so/bugbot)
- [feat: Add support for repository replication ](https://github.com/lgallard/terraform-aws-ecr/pull/55)</content><author><name>Luis M. Gallardo D.</name></author></entry><entry><title type="html"></title><link href="https://lgallardo.com/es/_i18n/es/2025-06-08-coding-agents-bugbot/" rel="alternate" type="text/html" title="" /><published>2025-06-09T07:19:12-05:00</published><updated>2025-06-09T07:19:12-05:00</updated><id>https://lgallardo.com/es/_i18n/es/2025-06-08-coding-agents-bugbot</id><content type="html" xml:base="https://lgallardo.com/es/_i18n/es/2025-06-08-coding-agents-bugbot/">&lt;p&gt;&lt;img src=&quot;/assets/images/coding-agents-bugbot-ac817363-8710-4b8f-a6a5-15e47cae8f8c.png&quot; alt=&quot;BugBot y Copilot: Revisores IA&quot; style=&quot;display:block; margin-left:auto; margin-right:auto; width:60%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Recientemente, mientras trabajaba en mis módulos de Terraform, se me ocurrió una idea: &lt;strong&gt;¿Y si uso BugBot para revisar el trabajo de los Coding Agents de Copilot?&lt;/strong&gt; Como ya estaba usando Copilot Coding Agents para automatizar PRs y refactorizaciones, decidí probar BugBot como revisor adicional.&lt;/p&gt;

&lt;h2 id=&quot;el-experimento&quot;&gt;El experimento&lt;/h2&gt;

&lt;p&gt;Asigné tareas a Copilot Coding Agents para implementar nuevas funcionalidades y correcciones en mis repositorios. Una vez listos los PRs, ejecuté BugBot para revisar los cambios. Los resultados fueron fascinantes:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/coding-agents-bugbot-2025-06-09_00-46.png&quot; alt=&quot;PR de Copilot con revisión de BugBot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;BugBot detectó rápidamente problemas que la propia revisión de Copilot no había visto, especialmente en casos límite y uso de variables. Su capacidad de detección de bugs está en otro nivel comparado con las revisiones integradas de Copilot.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/coding-agents-bugbot-2025-06-09_00-47.png&quot; alt=&quot;Reporte detallado de BugBot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Por ejemplo, BugBot señaló una validación regex demasiado restrictiva y variables no utilizadas en un PR generado por Copilot. Proporcionó retroalimentación accionable, que luego trasladé a Copilot para su corrección.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/coding-agents-bugbot2025-06-09_00-48.png&quot; alt=&quot;BugBot y Copilot: Revisores IA&quot; /&gt;&lt;/p&gt;</content><author><name>Luis M. Gallardo D.</name></author></entry><entry><title type="html"></title><link href="https://lgallardo.com/es/_i18n/es/2025-06-05-github-copilot-terraform-aws-backup.md/" rel="alternate" type="text/html" title="" /><published>2025-06-09T07:19:12-05:00</published><updated>2025-06-09T07:19:12-05:00</updated><id>https://lgallardo.com/es/_i18n/es/2025-06-05-github-copilot-terraform-aws-backup.md</id><content type="html" xml:base="https://lgallardo.com/es/_i18n/es/2025-06-05-github-copilot-terraform-aws-backup.md/">![GitHub Copilot Background Agents](/assets/images/copilot-coding-agent.png){:style=&quot;display:block; margin-left:auto; margin-right:auto;&quot;}

Recientemente tuve la oportunidad de probar los GitHub Copilot Coding Agents (Background Agents) en uno de mis proyectos personales: el módulo [terraform-aws-backup](https://github.com/lgallard/terraform-aws-backup). Este módulo está diseñado para ayudar a los usuarios a gestionar planes de AWS Backup usando Terraform.

## El problema

Un usuario abrió [un issue](https://github.com/lgallard/terraform-aws-backup/issues/114) solicitando soporte para múltiples planes de backup por vault. Esto requería un refactor importante del módulo, ya que previamente solo soportaba un plan por vault. Decidí asignar el issue a Copilot para ver cómo manejaba un refactor real de infraestructura como código (IaC).

![Asignación del issue a Copilot](/assets/images/copilot-assigned-by-lgallard.png)

## La solución de Copilot

Copilot Background Agents tomó el issue y propuso un pull request ([PR #115](https://github.com/lgallard/terraform-aws-backup/pull/115)) que introdujo una nueva variable `plans` (un mapa de mapas) para soportar múltiples planes de backup. El PR incluyó todos los cambios de código necesarios, actualizaciones de documentación y mantuvo la compatibilidad hacia atrás con el enfoque de un solo plan.

Interactué con Copilot directamente desde GitHub, haciendo preguntas y solicitando cambios. Por ejemplo, verifiqué la compatibilidad hacia atrás y reporté un caso especial relacionado con la migración del estado de Terraform. Copilot respondió a mis comentarios, resolvió los problemas y actualizó el PR en consecuencia.

![Conversación en el PR de Copilot](/assets/images/copilot-pr.png)

## Puntos destacados

- **Automatización de extremo a extremo:** Casi todo el proceso ocurrió dentro de GitHub, con mínima intervención humana.
- **Rapidez:** Todo el proceso de refactor y revisión tomó unos 35 minutos, de los cuales Copilot realizó la mayor parte en solo 13 minutos.
- **Flexibilidad de dispositivos:** Gestioné el proceso desde mi iPad mini usando Arc, sin necesidad de un IDE local.
- **Retroalimentación iterativa:** Copilot manejó varias rondas de feedback, incluyendo reportes de errores y ajustes de código.

## Desventajas

- **Selección de modelo:** No había opción para elegir qué modelo de IA usaba Copilot para la tarea.
- **Pruebas necesarias:** Como con cualquier generación automática de código, fue necesario probar y validar manualmente antes de hacer merge.
- **Manejo de imágenes:** Copilot no pudo leer imágenes pegadas en los comentarios, así que los errores debían proporcionarse en texto.

## Conclusión

GitHub Copilot Background Agents demostró ser una herramienta valiosa para tareas automatizadas y desatendidas como el refactor de módulos. Aunque es importante probar y validar el código generado, Copilot puede acelerar significativamente los flujos de trabajo de desarrollo, especialmente para infraestructura como código.

## Referencias

- [terraform-aws-backup module en GitHub](https://github.com/lgallard/terraform-aws-backup)
- [terraform-aws-backup module en Terraform Registry](https://registry.terraform.io/modules/lgallard/backup/aws)
- [GitHub Copilot Background Agents](https://docs.github.com/en/copilot)</content><author><name>Luis M. Gallardo D.</name></author></entry><entry><title type="html"></title><link href="https://lgallardo.com/es/_i18n/es/2024-05-12-anbernic-35xxh-batocera.md/" rel="alternate" type="text/html" title="" /><published>2025-06-09T07:19:12-05:00</published><updated>2025-06-09T07:19:12-05:00</updated><id>https://lgallardo.com/es/_i18n/es/2024-05-12-anbernic-35xxh-batocera.md</id><content type="html" xml:base="https://lgallardo.com/es/_i18n/es/2024-05-12-anbernic-35xxh-batocera.md/">![Anbernic 35xxH](/assets/images/anbernic-35xxh.jpg){:style=&quot;display:block; margin-left:auto; margin-right:auto&quot;}&lt;br/&gt;
Hoy en día, el mercado está inundado de una variedad de dispositivos portátiles para la emulación retro, provenientes de varias compañías chinas como [Retroid](https://www.goretroid.com/), [Powkiddy](https://powkiddy.com/), y [Anbernic](https://anbernic.com/). Estos dispositivos varían en factores de forma, desde pantallas compactas hasta capacidades de cómputo más potentes y sistemas operativos, algunos de los cuales son de código abierto, mientras que otros son propietarios y mantenidos por los fabricantes mismos.

Después de ver innumerables videos en YouTube, comparar especificaciones y explorar consolas retro en AliExpress con precios inferiores a $100, me encontré con la **Anbernic 35xxH**. Este modelo, con una pantalla de 3.5 pulgadas, es desarrollado por Anbernic. Es similar a la **Anbernic 35xx Plus** pero tiene una orientación horizontal. El nombre del modelo '35xxh' indica una pantalla de 3.5 pulgadas ('35xx') y una disposición horizontal ('h').

Como mencioné anteriormente, algunos sistemas operativos son desarrollados por los fabricantes de los dispositivos, como Anbernic, que ofrece un OS propietario. Aunque este sistema operativo cumple su propósito, no está exento de limitaciones. Por ejemplo, la manera en que se muestran y organizan los juegos puede ser confusa y engorrosa, y algunos emuladores funcionan mejor en RetroArch que en los emuladores independientes incluidos con el OS.

En busca de una interfaz más amigable para el usuario, me decanté por [Batocera](https://batocera.org/), un proyecto de código abierto mantenido por la comunidad. Batocera ofrece una interfaz de usuario más intuitiva y visualmente atractiva.

![Anbernic 35xxh](/assets/images/batocera-anbernic-35xxh.jpg){:style=&quot;display:block; margin-left:auto; margin-right:auto&quot;}&lt;br/&gt;

Para aquellos interesados en usar Batocera en su **Anbernic 35xxH**, existe un repositorio donde pueden descargar la imagen de Batocera, llamada [Batocera Lite Beta para RG35XX Plus y RG35XX H](https://github.com/rg35xx-cfw/rg35xx-cfw.github.io/discussions/104){:target=&quot;_blank&quot;}.

**References**
  * &lt;a href=&quot;https://www.goretroid.com/&quot; target=&quot;_blank&quot;&gt;Retroid&lt;/a&gt;
  * &lt;a href=&quot;https://powkiddy.com/&quot; target=&quot;_blank&quot;&gt;Powkiddy&lt;/a&gt;
  * &lt;a href=&quot;https://anbernic.com/&quot; target=&quot;_blank&quot;&gt;Anbernic&lt;/a&gt;
  * &lt;a href=&quot;https://batocera.org/&quot; target=&quot;_blank&quot;&gt;Batocera&lt;/a&gt;</content><author><name>Luis M. Gallardo D.</name></author></entry><entry><title type="html"></title><link href="https://lgallardo.com/es/_i18n/es/2023-12-18-aws-certified-solutions-architect-professional-2023.md/" rel="alternate" type="text/html" title="" /><published>2025-06-09T07:19:12-05:00</published><updated>2025-06-09T07:19:12-05:00</updated><id>https://lgallardo.com/es/_i18n/es/2023-12-18-aws-certified-solutions-architect-professional-2023.md</id><content type="html" xml:base="https://lgallardo.com/es/_i18n/es/2023-12-18-aws-certified-solutions-architect-professional-2023.md/">![OctoPrints](/assets/images/aws-csap-2023.jpg){:style=&quot;display:block; margin-left:auto; margin-right:auto&quot;}&lt;br/&gt;
Este artículo es para comentar mi experiecia con el examen para AWS Certified Solutions Architect - Professional (recertificación):

Si  vas a presentar el examen por primera vez o como mi caso buscas una recertificación, te recomiendo que revises los nuevos contenidos y que chequees qué ha cambiado respecto al examen anterior. Ejemplo de estos pueden ser AWS SSO por AWS Identity Center. También te recomiendo que sepas de qué van nuevos servicios como AWS Elastic Desaster Recovery, EventBridge, Amazon Managed Services for Apache Flink, entre otros.

Fueron 75 preguntas en 180 minutos. Como ya es clásico en las certificaciones profresionales de AWS, el examen es largo y tiene  enunciados extensos y con respuestas también extensas. Para quienes el inglés no es su lengua nativa puede llegar a ser confuso, por lo que seguro te tocará leer varias preguntas mas de una vez (y sus opcione).
Si  vas a presentar el examen por primera vex o como mi caso buscas una recertificación, te recomiendo que revises los nuevos contenidos y que chequees qué ha cambiado respecto al examen anterior. Ejemplo de estos pueden ser AWS SSO por AWS Identity Center. También te recomiendo que sepas de qué van nuevos servicios como AWS Elastic Desaster Recovery, EventBridge, Amazon Managed Services for Apache Flink, entre otros.
Mis recomendaciones para ganar tiempo en este examen son:

* Las preguntas fáciles respóndelas rápidamente, no te quedes mucho tiempo pensando en si es la respuesta correcta porque seguro lo es.
* Marcar las preguntas en las que realmente tienes dudas, así al momento de revisarlas puedes enfocarte en solo esas y si queda tiempo empezar a revisar el resto.
* Las preguntas con opciones míltiples márcalas para revisión, incluso si crees que están correctas. Te conviene estar 100% seguro de las opciones porque si te equivocas en una la respuesta puede ser considerada como inclorrecta.
* Lee bien las preguntas porque el eneunciado contiene la información que te va a ayudar a descartar opciones, o eligier las opciones correctas.
* Piensen que es una certificación de Amazon, en ese sentido siempre preguntarse cuál servicio de Amazon corresponde. 
* Descartar cosas que se pueden hacer a nivel de S.O. si un servicio de Amazon lo provee, y solo considerarlo cuando no hay mas opción.
* No todo se resuelve con Lambda + SQS, aunque suene correcto. Revisa qué opciones o servicios cumplen con lo que se esté solicitando y no dejarse marear por ociones que en principio parecen correctas.

Si estás interesado en esta certificación te recomiendo algunos enlaces:

**Cursos en línea**

Para este examen seguí fiel a AWS A Cloud Guru, pero para ser sinceros me parece que los conteidos los tratan superficialmente y el curso tal cual como está hoy en día parece un Frankeinstain ya que hay al menos dos instructores con formatos de contenidos distintos, como si hubiesen agarrado lo mejor de los curso de Linux Academy con los de A Cloud Guru . De Igual forma, si estás interesado acá lo tienes disponible:

  * &lt;a href=&quot;https://www.pluralsight.com/courses/aws-certified-solutions-architect-professional-sap-c02&quot; target=&quot;_blank&quot;&gt;A Cloud Guru - AWS Certified Solutions Architect Professional&lt;/a&gt;



**Documentación de AWS**

  * &lt;a href=&quot;https://aws.amazon.com/whitepapers/&quot; target=&quot;_blank&quot;&gt;Whitepapers&lt;/a&gt;
  * &lt;a href=&quot;https://aws.amazon.com/documentation/&quot; target=&quot;_blank&quot;&gt;Documentation&lt;/a&gt;
  * &lt;a href=&quot;https://aws.amazon.com/faqs/&quot; target=&quot;_blank&quot;&gt;FAQs&lt;/a&gt;</content><author><name>Luis M. Gallardo D.</name></author></entry><entry><title type="html"></title><link href="https://lgallardo.com/es/_i18n/es/2022-09-25-octoprint-multiple-printers.md/" rel="alternate" type="text/html" title="" /><published>2025-06-09T07:19:12-05:00</published><updated>2025-06-09T07:19:12-05:00</updated><id>https://lgallardo.com/es/_i18n/es/2022-09-25-octoprint-multiple-printers.md</id><content type="html" xml:base="https://lgallardo.com/es/_i18n/es/2022-09-25-octoprint-multiple-printers.md/">![OctoPrints](/assets/images/OctoPrint.jpg){:style=&quot;display:block; margin-left:auto; margin-right:auto&quot;}&lt;br/&gt;
Una de las herramientas más útiles a la hora de gestionar una impresora 3D es [OctoPrint](https://octoprint.org){:target=&quot;_blank&quot;}, ya que entre varias cosas permite administrar tu impresora desde una interfaz web, así como agregar un montón de funcionalidades (por ejemplo, monitoreo y gestión de la impresora a través de Telegram, plugins para generar los videos timelapse de las impresiones, o incluso detectar cuando hay problemas tipo espagueti en nuestra impresiones usando otro plugin con AI).

## Múltiples impresoras
¿Pero qué pasa si tenemos más de una impresora? ¿Puede **OctoPrint** gestionar mas de una impresora?
 
La respuesta corta es: NO! El software en sí no está diseñado para múltiples impresoras, pero se puede buscar formas alternativas para tener más de una instancia de **OctoPrint** corriendo en nuestro dispositivo o computadora.
  
Existen varias formas para esto, por ejemplo se puede [modificar los scripts de OctoPi para agregar más instancias](http://thomas-messmer.com/index.php/14-free-knowledge/howtos/79-setting-up-octoprint-for-multiple-printers){:target=&quot;_blank&quot;},  crear scripts que lancen varias instancias del mismo programa , pero la opción que terminé usando  fue la de contenedores Docker.
 
## Raspberry Pi + Ubuntu
 En mi caso tengo una **Raspberry Pi 4**, de 8 GB de RAM, más que suficiente para correr múltiples instancias de **OctoPrint**. 
 
En principio tenía instalado en mi Raspberry un sistema operativo específico llamado [OctoPi](https://github.com/guysoft/OctoPi){:target=&quot;_blank&quot;}, un derivado de Debian con **OctoPrint** como el programa principal que se lanza cuando se enciende el dispositivo, pero al querer tener contenedores pensé en usar Ubuntu que es una distribución menos especializada y donde seguramente se puede encontrar todo lo necesario para trabajar con contenedores.
 
## Requisitos y componentes:
Para esta configuración usé lo siguiente:

* Impresora 3D - Artillery Genius Pro
* Impresora 3D - Artillery SideWinder X2
* 2x WebCam - Logitech C270 (una por impresora)
* Raspberry Pi 4 - 8G RAM
* SD Card 64 GB
* Ubuntu 22.04 LTS  ARM 64 bits
* Docker 20.10.17
* OctoPrint lastest (1.8.3)

## Instalación de Ubuntu
Para instalar **Ubuntu** en la Raspberry Pi ahora es más sencillo que nunca, solo tienes que descargar **Raspberry Pi Imager,** el cual generará la imagen en tu tarjeta SD, seleccionar el sistema operativo, que en este caso es **Ubuntu 22.04 LTS** y listo. Hay versiones de Raspberry Pi Imager para Linux, Mac y Windows, así que podrás generar la imagen en el sistema operativo que más te convenga.

![Raspberry Pi Imager](/assets/images/Raspberry-Pi-Imager.jpg)

Desde este mismo software vas a tener la posibilidad de configurar la contraseña de la red WiFi en caso de que la estés usando la Raspberry de forma inalámbrica y que no quieras usar un televisor y un teclado (headless), o tocar la SD para configurar la red. Como yo lo estoy usando headless, fue lo que hice y luego me conecté por **ssh**.

![WiFi Settings](/assets/images/OctoPi-WiFi-Setting.jpg)

Para la configuración headless el truco es dejar que corran los scripts de inicialización de **Ubuntu** y luego conectarte por ssh. Ahora si ves que no puedes conectarse por ssh puedes buscar un cable HDMI y un teclado para revisar qué pueda estar pasando.

## Instalación del software en Ubuntu
Aparte de **Docker** vamos a necesitar, **docker-compose**, y los utilitarios que nos ayudarán a instalarlos.

## Docker y docker-compose
Para instalar docker debemos descargarlo usando el script. Necesitaremos entrar como usuario administrador con la cuenta root:

```bash
pi@octopi:~$ sudo su
root@octopi:~# 

root@octopi:~# apt install curl
root@octopi:~# curl -sSL https://get.docker.com | sh

root@octopi:~# apt update
root@octopi:~# apt install docker-compose
```

## OctoPrint con una impresora
Lo primero que haremos es crear un carpeta para OctoPrint, y luego entrar en ella:

```bash
root@octopi:~# mkdir octoprint
root@octopi:~# 
root@octopi:~# cd octoprint/
root@octopi:~/octoprint#
```

Vamos a empezar con una impresora, en este caso empezaré con la `Artillery Genius Pro`.  Para esto creamos una carpeta que identifique a esta impresora:

```bash
root@octopi:~# mkdir geniuspro
root@octopi:~# chmod -R 777 geniuspro/
```

Es importante saber la ruta actual porque luego la usaremos en la definición del contenedor junto con el nombre de esta carpeta. Para ello ejecutamos la siguiente orden:

```bash
root@octopi:~# pwd
/root/octoprint
```

Ya con esto podemos indicar luego que los archivos de esta primera instancia de OctoPrint residirán en `/root/octoprint/geniuspro`.

Ahora para configurar la impresora vamos a usar `docker-compose` por lo que creamos el archivo `docker-compose.yml` con la siguiente información:

```
version: '2.4'

services:
  geniuspro:
    image: octoprint/octoprint
    restart: unless-stopped
    ports:
      - 5000:5000
      - 8080:8080
    devices:
      - /dev/ttyACM0:/dev/ttyACM0
      - /dev/video0:/dev/video0
    volumes:
      - /root/octoprint/geniuspro:/octoprint
    # uncomment the lines below to ensure camera streaming is enabled when
    # you add a video device
    environment:
      - ENABLE_MJPG_STREAMER=true
      - CAMERA_DEV=/dev/video0
      - MJPG_STREAMER_INPUT=&quot;-y -n -r 1280x960 -f 30
```

Este archivo define varias cosas relacionadas a OctoPrint, como la cámara web y la impresora como tal. Por ejemplo, con `image` indicamos cuál es la imagen Docker a usar para el servicio `geniuspro`.  

En esta definición hay que destacar los puertos, los cuales serán usados para acceder a los servicios, siendo el `5000` para la interfaz web y el `8080` para el streaming de video de la cámara web.

Por otro lado se define como dispositivo la impresora en `/dev/ttyACM0`, y la cámara web en `/dev/video0`

Algo a tener en cuenta y que se diferencia del [ejemplo en cuál me basé](https://docs.google.com/document/d/1aU7LGYAe6r45LqEBQ8opuXCiNKeJl3XrPTrobvEvdOM/edit){:target=&quot;_bla￼nk&quot;}, es que el streamer ahora es parte de la imagen Docker y es atendido en el puerto `8080`, por los que no hace falta tener una definición aparte a otra imagen Docker apuntando al streamer.

Luego en `volumes` es donde se hace la referencia al directorio de la impresora que habíamos creado en la ruta  `/root/octoprint/geniuspro`, que será mapeada  dentro del contenedor en  la carpeta `/octoprint`. Es decir, cuando levantemos el contenedor todos los archivos de OctoPrint para esta impresora quedarán en la ruta `/root/octoprint/geniuspro` del sistema operativo.

Por último, en `environment` definimos los parámetros para el streamer, pasando la información del dispositivo de la cámara web referido desde el contenedor, que en este caso coincide con el del sistema operativo afitrión, es decir, `/dev/video0`. También le proporcionamos los parámetros de la cámara, en mi caso le indico que la resolución es de 1280x960 a 30 frames por segundos, que es lo que corresponde com mi Logitech C270. Para otros modelos puedes consultar el [listado desde la  página de cámaras soportadas](https://community.octoprint.org/t/usb-webcams-known-to-work-with-mjpg-streamer/21149){:target=&quot;_bla￼nk&quot;}.

Una vez creado el archivo  `docker-compose.yml` con la información mostrada arriba, solo basta con levantar el servicio con Docker:

```
root@octopi:~/octoprint# docker-compose up -d
  
Creating octoprint_geniuspro_1 ... done
```

Ya con esto podemos acceder a la interfaz web de OctoPrint desde la ip de la Raspberry en el puerto que le habíamos indicado, que en mi caso la url es http://192.168.68.102:5000:

![OctoPrint Web 1](/assets/images/octoprint-multi-web.jpg)

## Agregar una segunda impresora 
Para agregar una segunda impresora solo hay que replicar la configuración que teníamos antes, pero especificando la nueva impresora y la cámara de video correspondiente. Entonces para mi Artillery Sidewinder X2 esto sería:

```
version: '2.4'

services:
  geniuspro:
    image: octoprint/octoprint
    restart: unless-stopped
    ports:
      - 5000:5000
      - 8080:8080
    devices:
      - /dev/ttyACM0:/dev/ttyACM0
      - /dev/video0:/dev/video0
    volumes:
      - /root/octoprint/geniuspro:/octoprint
    # uncomment the lines below to ensure camera streaming is enabled when
    # you add a video device
    environment:
      - ENABLE_MJPG_STREAMER=true
      - CAMERA_DEV=/dev/video0
      - MJPG_STREAMER_INPUT=&quot;-y -n -r 1280x960 -f 30
 
  sidewinder_x2:
    image: octoprint/octoprint
    restart: unless-stopped
    ports:
      - 5000:5000
      - 8080:8080
    devices:
      - /dev/ttyACM1:/dev/ttyACM0
      - /dev/video2:/dev/video0
    volumes:
      - /root/octoprint/geniuspro:/octoprint
    # uncomment the lines below to ensure camera streaming is enabled when
    # you add a video device
    environment:
      - ENABLE_MJPG_STREAMER=true
      - CAMERA_DEV=/dev/video0
      - MJPG_STREAMER_INPUT=&quot;-y -n -r 1280x960 -f 30

```

Aquí hay que aclarar que en el apartado devices físicamente la impresora está identificada en la Raspberry como `/dev/ttyACM1`, pero al crear el contenedor internamente se identificará como `/dev/ttyACM0`. Lo mismo pasa con la cámara de video, donde físicamente se identifca como `/dev/video2` pero internamente el contenedor la verá como `/dev/video0`.

Una vez creada la configuración se debe levantar el contendor de la siguiente manera: 

```
root@octopi:~/octoprint# docker-compose up -d
  
octoprint_geniuspro_1 is up-to-date
Creating octoprint_sidewinderx2_1 ... done
```

Con esto ya se podrá acceder a la segunda instancia de OctoPrint en el puerto 5001:

![OctoPrint Web 2](/assets/images/octoprint-multi-web2.jpg)

## ¿Cómo diferenciar las impresoras?
En el anterior ejemplo usé los dipositivos `/dev/ttyACM0` y `/dev/ttyACM1`  para hacer referencia a mi primera impresora, la Artillery Genius Pro, y a la segunda impresora la Artillery SideWinder X2, pero el sistema operativo no siempre las tomará en ese orden, ya que dependerá de cuál encienda primero . Para poder identificar las impresoras sin importar el orden de conexión podemos crear un enlace simbólico usando `udev` con la información del fabricante y del producto.

Para esto primero hay que listar los dispositivos USB:

```
root@octopi:~/octoprint# lsusb
Bus 003 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub
Bus 002 Device 001: ID 1d6b:0003 Linux Foundation 3.0 root hub
Bus 001 Device 004: ID 046d:0825 Logitech, Inc. Webcam C270
Bus 001 Device 003: ID 046d:0825 Logitech, Inc. Webcam C270
Bus 001 Device 015: ID 0483:5740 STMicroelectronics Virtual COM Port
Bus 001 Device 016: ID 0483:5740 STMicroelectronics Virtual COM Port
Bus 001 Device 002: ID 2109:3431 VIA Labs, Inc. Hub
Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub
```

Acá hay dos dispositivos de **STMicroelectronics Virtual COM Port**, que corresponden a las dos impresoras, pero cuál es cuál? Vamos a pedir el detalle de estos dispositivos:
 
```
 root@octopi:~/octoprint# lsusb -v -d 0483:5740

Bus 001 Device 015: ID 0483:5740 STMicroelectronics Virtual COM Port
Device Descriptor:
  bLength                18
  bDescriptorType         1
  bcdUSB               2.00
  bDeviceClass            2 Communications
  bDeviceSubClass         2 Abstract (modem)
  bDeviceProtocol         0
  bMaxPacketSize0        64
  idVendor           0x0483 STMicroelectronics
  idProduct          0x5740 Virtual COM Port
  bcdDevice            0.00
  iManufacturer           1 STMicroelectronics
  iProduct                2 ARTILLERY_RUBY CDC in FS Mode
  iSerial                 3 386F39543538  
...
  
Bus 001 Device 016: ID 0483:5740 STMicroelectronics Virtual COM Port
Device Descriptor:
  bLength                18
  bDescriptorType         1
  bcdUSB               2.00
  bDeviceClass            2 Communications
  bDeviceSubClass         2 Abstract (modem)
  bDeviceProtocol         0
  bMaxPacketSize0        64
  idVendor           0x0483 STMicroelectronics
  idProduct          0x5740 Virtual COM Port
  bcdDevice            0.00
  iManufacturer           1 STMicroelectronics
  iProduct                2 ARTILLERY_RUBY CDC in FS Mode
  iSerial                 3 3594398F3538  
...
```

Lo que diferenica una impresora de la otra es el número serial del dispositivo. Como inicialmente la Artillery Genius Pro estaba mapeada en `/dev/ttyACM0`, podemos consultar cuál es su número de serial:
 
```
root@octopi:~/octoprint# udevadm info -a -n /dev/ttyACM0 | grep serial
    ATTRS{serial}==&quot;3594398F3538&quot;
    ATTRS{serial}==&quot;0000:01:00.0&quot;
```

Ahora para la ver el código serial de la Artillery Sidewinder X2 se debe consultar por el dispositivo `/dev/ttyACM1`:
 
```

root@octopi:~/octoprint# udevadm info -a -n /dev/ttyACM1 | grep serial
    ATTRS{serial}==&quot;386F39543538&quot;
    ATTRS{serial}==&quot;0000:01:00.0&quot; 
```

Para que  `udev`  reconozca estas reglas debemos crear el siguiente archivo `/etc/udev/rules.d/40-printers.rules` , con este contenido:
 
```
 # Genius Pro
KERNEL==&quot;ttyACM[0-9]*&quot;, SUBSYSTEM==&quot;tty&quot;, ATTRS{idVendor}==&quot;0483&quot;, ATTRS{idProduct}==&quot;5740&quot;, ATTRS{serial}==&quot;3594398F3538&quot;, SYMLINK=&quot;ttyGeniusPro&quot;

# Sidewinder X2
KERNEL==&quot;ttyACM[0-9]*&quot;, SUBSYSTEM==&quot;tty&quot;, ATTRS{idVendor}==&quot;0483&quot;, ATTRS{idProduct}==&quot;5740&quot;, ATTRS{serial}==&quot;386F39543538&quot;, SYMLINK=&quot;ttySidewinderX2&quot;
```
 
 Luego se debe reiniciar `udev` para que tome estos cambios:
  
```
root@octopi:~/octoprint# udevadm control --reload-rules &amp;&amp; udevadm trigger
```

De esta manera quedarán las impresoras mapeadas de la siguiente forma:  
  
```
root@octopi:~/octoprint# ls -l  /dev/tty{GeniusPro,Sidewinder}*
lrwxrwxrwx 1 root root 7 Aug 22 21:10 /dev/ttyGeniusPro -&gt; ttyACM0
lrwxrwxrwx 1 root root 7 Aug 22 21:10 /dev/ttySidewinderX2 -&gt; ttyACM1
```

Por lo que la configuración de Docker podemos modificarla para reflejar estos cambios:  
  
```
version: '2.4'

services:
  geniuspro:
    image: octoprint/octoprint
    restart: unless-stopped
    ports:
      - 5000:5000
      - 8080:8080
    devices:
      - /dev/ttyGeniusPro:/dev/ttyACM0
      - /dev/video0:/dev/video0
    volumes:
      - /root/octoprint/geniuspro:/octoprint
    # uncomment the lines below to ensure camera streaming is enabled when
    # you add a video device
    environment:
      - ENABLE_MJPG_STREAMER=true
      - CAMERA_DEV=/dev/video0
      - MJPG_STREAMER_INPUT=&quot;-y -n -r 1280x960 -f 30

  sidewinderx2:
    image: octoprint/octoprint
    restart: unless-stopped
    ports:
      - 5001:5000
      - 8081:8080
    devices:
      - /dev/ttySidewinderX2:/dev/ttyACM0
      - /dev/video2:/dev/video0
    volumes:
      - /root/octoprint/sidewinderx2:/octoprint
    # uncomment the lines below to ensure camera streaming is enabled when
    # you add a video device
    environment:
      - ENABLE_MJPG_STREAMER=true
      - CAMERA_DEV=/dev/video0
      - MJPG_STREAMER_INPUT=&quot;-y -n -r 1280x960 -f 30  

```

## Cámaras de video
A diferencia de las impresoras las cuales tienen seriales distintos, tengo dos cámaras de video **Logitech C270** que son exaxtamente iguales. ¿Cómo hacemos para diferenciarlas? ¿Cómo podemos hacer que siempre tome la cámara correcta?

Nuevamente hacemos el análisis con  `lsusb`:

```
root@octopi:~/octoprint# lsusb
Bus 003 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub
Bus 002 Device 001: ID 1d6b:0003 Linux Foundation 3.0 root hub
Bus 001 Device 004: ID 046d:0825 Logitech, Inc. Webcam C270
Bus 001 Device 003: ID 046d:0825 Logitech, Inc. Webcam C270
Bus 001 Device 015: ID 0483:5740 STMicroelectronics Virtual COM Port
Bus 001 Device 016: ID 0483:5740 STMicroelectronics Virtual COM Port
Bus 001 Device 002: ID 2109:3431 VIA Labs, Inc. Hub
Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub
```

Ambas cámaras están en el mismos bus pero identificadas como dispositivos USB diferentes, lo cual podemos aprovechar. En este caso no usaremos el id del producto para diferenciarlas sino el id de dispositivo USB.  Tomaremos como referencia el subsystem `video4linux` en vez de `tty`, por lo que estaremos usando `KERNELS` en vez de `KERNEL` para diferenciar las cámaras. Por ejemplo, para saber en qué dispositivo USB está  la cámara en `/dev/video0` podemos ejecutar lo siguiente:

```
root@octopi:~/octoprint# udevadm info -a -p  $(udevadm info -q path -n /dev/video0) | grep KERNELS
    KERNELS==&quot;1-1.4:1.0&quot;
    KERNELS==&quot;1-1.4&quot;
    KERNELS==&quot;1-1&quot;
    KERNELS==&quot;usb1&quot;
    KERNELS==&quot;0000:01:00.0&quot;
    KERNELS==&quot;0000:00:00.0&quot;
    KERNELS==&quot;pci0000:00&quot;
    KERNELS==&quot;fd500000.pcie&quot;
    KERNELS==&quot;scb&quot;
    KERNELS==&quot;platform&quot;
```

Para la otra cámara hacemos lo mismo:

```
root@octopi:~/octoprint# udevadm info -a -p  $(udevadm info -q path -n /dev/video2) | grep KERNELS
    KERNELS==&quot;1-1.3:1.0&quot;
    KERNELS==&quot;1-1.3&quot;
    KERNELS==&quot;1-1&quot;
    KERNELS==&quot;usb1&quot;
    KERNELS==&quot;0000:01:00.0&quot;
    KERNELS==&quot;0000:00:00.0&quot;
    KERNELS==&quot;pci0000:00&quot;
    KERNELS==&quot;fd500000.pcie&quot;
    KERNELS==&quot;scb&quot;
    KERNELS==&quot;platform&quot;
```

Ya con esta información podemos modificar las reglas de `udev` de la siguiente manera:

```
# Genius Pro
KERNEL==&quot;ttyACM[0-9]*&quot;, SUBSYSTEM==&quot;tty&quot;, ATTRS{idVendor}==&quot;0483&quot;, ATTRS{idProduct}==&quot;5740&quot;, ATTRS{serial}==&quot;3594398F3538&quot;, SYMLINK=&quot;ttyGeniusPro&quot;
SUBSYSTEM==&quot;video4linux&quot;, KERNELS==&quot;1-1.3&quot;, ATTRS{idVendor}==&quot;046d&quot;, ATTRS{idProduct}==&quot;0825&quot;, SYMLINK=&quot;videoGeniusPro&quot;

# Sidewinder X2
KERNEL==&quot;ttyACM[0-9]*&quot;, SUBSYSTEM==&quot;tty&quot;, ATTRS{idVendor}==&quot;0483&quot;, ATTRS{idProduct}==&quot;5740&quot;, ATTRS{serial}==&quot;386F39543538&quot;, SYMLINK=&quot;ttySidewinderX2&quot;
SUBSYSTEM==&quot;video4linux&quot;, KERNELS==&quot;1-1.4&quot;, ATTRS{idVendor}==&quot;046d&quot;, ATTRS{idProduct}==&quot;0825&quot;, SYMLINK=&quot;videoSidewinderX2&quot;
```

Recuerden reiniciar las reglas de udev con:

```
root@octopi:~/octoprint# udevadm control --reload-rules &amp;&amp; udevadm trigger
```

De esta forma ahora tenemos las cámaras mapeadas como `/dev/videoGeniusPro`y  `/dev/videoSidewinderX2` respectivamente. Ahora podemos modificar el archivo **docker-compose.yml** para que tome esta nueva configuración:

```
version: '2.4'

services:
  geniuspro:
    image: octoprint/octoprint
    restart: unless-stopped
    ports:
      - 5000:5000
      - 8080:8080
    devices:
      - /dev/ttyGeniusPro:/dev/ttyACM0 # use `python -m serial.tools.miniterm` to see what the name is of the printer, this requires pyserial
      - /dev/videoGeniusPro:/dev/video0
    volumes:
      - /root/octoprint/geniuspro:/octoprint
    # uncomment the lines below to ensure camera streaming is enabled when
    # you add a video device
    environment:
      - ENABLE_MJPG_STREAMER=true
      - CAMERA_DEV=/dev/video0
      - MJPG_STREAMER_INPUT=&quot;-y -n -r 1280x960 -f 30

  sidewinderx2:
    image: octoprint/octoprint
    restart: unless-stopped
    ports:
      - 5001:5000
      - 8081:8080
    devices:
      - /dev/ttySidewinderX2:/dev/ttyACM0 # use `python -m serial.tools.miniterm` to see what the name is of the printer, this requires pyserial
      - /dev/videoSidewinderX2:/dev/video0
    volumes:
      - /root/octoprint/sidewinderx2:/octoprint
    # uncomment the lines below to ensure camera streaming is enabled when
    # you add a video device
    environment:
      - ENABLE_MJPG_STREAMER=true
      - CAMERA_DEV=/dev/video0
      - MJPG_STREAMER_INPUT=&quot;-y -n -r 1280x960 -f 30
```

## Desempeño con dos instancias de OctoPrint
Seguramente te estarás preguntando sobre el consumo de estos contenedores en el sistema operativo y si las Raspberry puede manejarlo. Aquí te dejo una imagen de `htop` con los dos contenedores arriba imprimiendo en cada una de las impresoras a la vez. 

![htop](/assets/images/octoprint-htop.jpg)

Como pordás notar la Raspberry está holgada, ya que de los 8GB de RAM apenas está consumiendo 0.5 GB incluyendo el sistema operativo. De esto podemos sacar dos conclusiones: la primera es que se pueden agregar más impresoras sin problemas, el único límite es la cantidad de puertos USB que ofrece las Raspberry (4 en mi modelo), pero podrías agregar un hub USB para agregar puertos; y lo segundo es que para dos impresoras se podría usar una Raspberry con menos RAM, por ejemplo de 2 GB o 4 GB, y así economizar un poco.

## ¿Cómo luce las impresoras y la Raspberry Pi?

Para cerrar este artículo les dejo una foto de mis impresoras conectadas a la RaspBerry Pi:

![3D printers](/assets/images/3dprinters.jpg)

En la impresora más chica puede verse una caja pequeña gris que es la Raspberry Pi, junto a las dos cámaras web.


# Referencias
* [OctoPrint](https://octoprint.org){:target=&quot;_blank&quot;}
* [OctoPi](https://github.com/guysoft/OctoPi){:target=&quot;_blank&quot;}
* [Setting up OctoPrint on a Raspberry Pi for multiple printers](http://thomas-messmer.com/index.php/14-free-knowledge/howtos/79-setting-up-octoprint-for-multiple-printers){:target=&quot;_blank&quot;}
* [Installing OctoPrint using Docker in Linux (video tutorial)](https://youtu.be/LcA9o6OGfEg){:target=&quot;_blank&quot;}
* [Installing OctoPrint using Docker in Linux (instructions)](https://docs.google.com/document/d/1aU7LGYAe6r45LqEBQ8opuXCiNKeJl3XrPTrobvEvdOM/edit){:target=&quot;_blank&quot;}
* [USB webcams known to work with mjpg-streamer](https://community.octoprint.org/t/usb-webcams-known-to-work-with-mjpg-streamer/21149){:target=&quot;_bla￼nk&quot;}.
* [How to distinguish between identical USB-to-serial adapters?](https://askubuntu.com/questions/49910/how-to-distinguish-between-identical-usb-to-serial-adapters){:target=&quot;_blank&quot;}
* [Udev Rule to discern 2 identical webcams on Linux](https://unix.stackexchange.com/questions/424887/udev-rule-to-discern-2-identical-webcams-on-linux){:target=&quot;_blank&quot;}</content><author><name>Luis M. Gallardo D.</name></author></entry><entry><title type="html"></title><link href="https://lgallardo.com/es/_i18n/es/2022-04-17-paperlike-pencil-grips.md/" rel="alternate" type="text/html" title="" /><published>2025-06-09T07:19:12-05:00</published><updated>2025-06-09T07:19:12-05:00</updated><id>https://lgallardo.com/es/_i18n/es/2022-04-17-paperlike-pencil-grips.md</id><content type="html" xml:base="https://lgallardo.com/es/_i18n/es/2022-04-17-paperlike-pencil-grips.md/">![PaperLike Pencil Grips](/assets/images/PaperLike-Pencil-Grip.jpg){:style=&quot;display:block; margin-left:auto; margin-right:auto&quot;}&lt;br/&gt;
Vengo usando ya desde hace un tiempo mi iPad para tomar notas con el Apple Pencil y decidí escribir este artículo para comentarles sobre un producto que me ha sorprendido gratamente y que pienso que es una excelente mejora a considerar: **Paper Like Pencil Grips**.

Puede que te haya pasado que al usar por mucho tiempo el Apple Pencil se te cansa la mano? Esto es algo común incluso con lápices tradicionales, y para esto ya existía una solución, los clásicos agarradores que se adaptan al lápiz para mejorar la postura de los dedos al escribir. Esto fue lo que terminó diseñando el equipo de PaperLike, pero para el Apple Pencil.

Seguramente dirás que son unos simple agarradores y que puedes usar unos agarradores tradicionales y adaptarlos al Apple Pencil...Si, por poco dinero puedes colocarle un agarrador genérico pero hay algunas cosas que debes considerar, que ya resolvió el equipo de PaperLike y que no tendrás con un producto genérico:

## La carga magnética del Apple Pencil
![Blink config](/assets/images/Grip-on-iPad.jpg){:style=&quot;display:block; margin-left:auto; margin-right:auto&quot;}

Esto lo consiguen gracias a que sus agarradores están diseñadas especialmente para el Apple Pencil, ya que tienen la forma del lápiz, y el lado que se usa para la carga magnética es ligeramente más delgado.

## La postura de los dedos.
La gente de PaperLike tomaron en cuenta dos casos de borde: precisión y periodos prolongados de uso. Si, vienen dos agarradores de lápiz distintos: El primero está orientado a tener una máxima precisión al agarrar el lápiz para, por ejemplo, cuando necesitas detalles finos a la hora de dibujar. El segundo está pensado para ayudar a quienes toman notas por mucho tiempo, ideal para estudiantes universitarios.

En mi caso particular disfruto mucho el agarrador de uso extendido (aunque hace tiempo que dejé los estudios universitarios atrás), pero estoy seguro que a los estudiantes les será de mucha utilidad, así como a los artistas (profesionales o no) les será de mucha utilidad poder tener trazos más precedidos a la hora de hacer sus creaciones.

## Función de doble tap
El Apple Pencil tiene una segunda función que se activa haciendo un doble toque sobre la parte plana del lápiz. Con un agarrador genérico no hay forma que el doble tap funcione.  En el caso de los agarradores de lápiz PaperLike, esto lo consiguen con la parte más delgada del agarrador. Pero debo comentar que para usarlo hay que girar el lápiz para poder hacer el double tap. Esto lo uso mucho en **GoodNotes 5**, y no es tan natural. De hecho el fundador del PaperLike en el video de explicación comenta que una opción es usar el agarrador con esa parte hacia arriba, pero considero que pierde la gracia ya que la forma del agarrador está diseñada para los dedos índices y el pulgar. Me parede que mejor opción es acostunbrarse a girar el lapiz antes de hacer el double tap, y volverlo a girar para contunuar escribiendo.

# El empaque
Por último, me gustaría resaltar algo grato que es el empaque en el que vino. Como los agarradores las compré en una etapa temprana, los mismos vinieron en un sobre de papel, que de hecho aclaran que no es el empaque final del producto. 

![Envoltorio de los PaperLike Pencil Grips](/assets/images/PaperLike-Pencil-Grips-Envelop.jpg){:style=&quot;display:block; margin-left:auto; margin-right:auto&quot;}

En particular no me molesta para nada y de hecho hasta diría que debería ser la version final, una presentación sencilla y bastante amigable con el medio ambiente. Lo único que mejoraría es el material del sobre sea un poco más duro para que resista los embates del viaje, o en su defecto que las envíen en correspondencia &quot;frágil&quot;, ya que el envío no fue nada económico  (€ 39.99). En mi caso los míos llegaron en ese sobre un poco arrugado, y el contenido también se arrugó.
 
Otros detalles que me gustaron fueron la nota de agradecimiento que colocan en el empaqué, escrita a mano por el fundador de PaperLike (y luego impresa de manera industrial), así como un sticker muy bonito que agregan de la comunidad de artistas que usan sus productos.

![Agradecimientos de PaperLike Pencil Grips](/assets/images/PaperLike-Pencil-Grips-thanks.jpg){:style=&quot;display:block; margin-left:auto; margin-right:auto&quot;}

![Stricker de regalo PaperLike Pencil Grips](/assets/images/PaperLike-Pencil-Grips-Sticker.jpg){:style=&quot;display:block; margin-left:auto; margin-right:auto&quot;}

# ¿Dónde comprar las agarraderas de PaperLike?
Como les comenté, están en una etapa temprana,por lo que de momento el único sitio donde los encontrarás es en la tienda de PaperLike, en [los accesorios para iPad](https://paperlike.com/collections/ipad-accessories){:target=&quot;_blank&quot;} , en particular acá están publicados los [PaperLike Pencil Grips ](https://paperlike.com/collections/ipad-accessories/products/pencil-grip-set){:target=&quot;_blank&quot;}

# Conclusión
Si necesitas un agarrador para tu Apple Pencil, ten en cuenta esta opción que ofrece la gente de PaperLike, que sin duda mejorará notablemente tu experiencia de uso en tu iPad.

## Nota
Este artículo lo hice para compartir mi experiencia con los agarradores de lápiz de PaperLike, y no recibí ningún patrocinio ni tengo ninguna ganancia o participación en las ventas de los mismas.

ß# Referencias
* [Página de PaperLike](https://paperlike.com){:target=&quot;_blank&quot;}
* [Accesorios para iPad](https://paperlike.com/collections/ipad-accessories){:target=&quot;_blank&quot;}
* [Agarradores de lápiz de PaperLike](https://paperlike.com/collections/ipad-accessories/products/pencil-grip-set){:target=&quot;_blank&quot;}</content><author><name>Luis M. Gallardo D.</name></author></entry><entry><title type="html"></title><link href="https://lgallardo.com/es/_i18n/es/2022-01-25-ipad-pro-as-a-portable-workstation.md/" rel="alternate" type="text/html" title="" /><published>2025-06-09T07:19:12-05:00</published><updated>2025-06-09T07:19:12-05:00</updated><id>https://lgallardo.com/es/_i18n/es/2022-01-25-ipad-pro-as-a-portable-workstation.md</id><content type="html" xml:base="https://lgallardo.com/es/_i18n/es/2022-01-25-ipad-pro-as-a-portable-workstation.md/">![iPad Pro](/assets/images/ipad-pro-2021.jpg){:style=&quot;display:block; margin-left:auto; margin-right:auto&quot;}&lt;br/&gt;
Hace un tiempo que no escribía en el blog, primero porque no encontraba algo interesante para compartir y segundo porque no había mucho tiempo de sobra (no es que ahora haya mucho tiempo de sobra pero bueno, se busca siempre un espacio para escribir unas líneas).

Lo cierto es que hace poco me hice con un iPad Pro de 11&quot; y dentro de las cosas que estuve probando fue la posibilidad de usarlo como equipo de trabajo ligero, es decir, un equipo que pueda tener a la mano en mi mesa de noche sin que sea una computadora completa.

Si bien el iPad tiene muchas ventajas y cosas que me gustaron, el termino &quot;Pro&quot; no da como para tener una terminal completa de un sistema operativo o tener una [máquina virtual funcional](https://youtu.be/LrLDKYFyLMM){:target=&quot;_blank&quot;}, por lo que decidí investigar a ver si existía alguna opción y de las cosas que más tuvieron sentido para mí fue la de usar el iPad Pro como un cliente que se conecta a alguna otra parte donde si pueda tener acceso a un sistema operativo completo.

De hecho en un [artículo](https://arslan.io/2019/01/07/using-the-ipad-pro-as-my-development-machine/){:target=&quot;_blank&quot;} que conseguí sugerían la opción de usar un Digital Ocean Droplet para tener una máquina virtual en la nube y desde ahí poder trabajar. Esta opción no es mala, pero teniendo una estación de trabajo en casa no vi la necesidad de irme a la nube.

Siguiendo algunas de estas sugerencias terminé instalando **Blink Shell** que viene con soporte para `mosh`, y usando `tmux` en mi laptop con Linux como sitio remoto pude hacerlo. A continuación les comento el detalle de esta configuración.

# Blink Shell (ssh / mosh)

Lo primero que tuve que buscar fue un cliente `ssh` decente para iPad. Dentro de las recomendaciones recurrentes en Internet **[Blink Shell](https://blink.sh){:target=&quot;_blank&quot;}** aparecía como una opción. En principio el hecho de que haya que comprarlo sin  un trial no gustaba pero como insistían en que era la mejor opción decidí probarlo (USD 19,99 a la fecha de publicación de este post).

Tengo que decir que **Blink Shell** es muy pero muy bueno, está diseñado para dispositivos móviles y tiene soporte para `mosh`.

## Mosh

Te estarás preguntando como en su momento lo hice yo ¿Qué es `mosh`? La [página de mosh](https://mosh.org){:target=&quot;_blank&quot;} dice lo siguiente:

&gt; Aplicación de terminal remoto que permite la itinerancia, admite conectividad intermitente y proporciona eco local inteligente y edición de línea de las pulsaciones de teclado del usuario.

¿Sigues sin entender para qué sirve `mosh` como me pasaba a mí? Es como `screen` pero sin tener que aprender comandos para crear y manejar sesiones, además  por debajo utliza `ssh`.  En otras palabras, vas a tener la posibilidad de continuar con tu sesión de trabajo donde la dejaste, o si por ejemplo se te cortó la conexión y logras conectarte de nuevo con otra red.

Como por debajo se seguimos teniendo `ssh`, para usar `mosh` la sintaxis es prácticamente la misma.  Es decir, si antes te conectabas con `ssh` a un servidor de esta manera:

```
ssh lgallard@192.168.1.65
```

Ahora con `mosh` lo haces de esta forma:

```
mosh lgallard@192.168.1.65
```

Parece sencillo el cambio y con esto ganamos que al cerrar nuestro iPad o el equipo donde estanos usando el cliente `mosh` vamos a poder recuperar mágicamente la sesión de trabajo al volvernos a conectar.

Puedes configurar las opciones de **Blink Shell** accediendo a un asistente de configuración para tener distintos hosts y facilitar la conexión con un nombre en vez de una dirección IP. Para acceder a este asistente basta con escribir `config` desde el terminal:

![Blink config](/assets/images/Blink_config.png){:style=&quot;display:block; margin-left:auto; margin-right:auto&quot;}

En mi caso ahora me puedo conectar a mi estación de trabajo de la siguiente forma:

```
mosh dauntless
```

## Mosh, lo malo

El gran punto en contra de `mosh` es que no puedes hacer scroll del terminal, es decir, si necesitas consultar la salida de comandos que hayas ejecutado previamente y que ya no estén en la pantalla, no los vas a poder ver. Esto para mí era un gran problema porque al usar `terraform` perdía los planes con los cambios a ser aplicados.

Esta es la forma en que trabaja `mosh`, para tener un óptimo rendimiento hacen un rendering del texto. Hay un [issue abierto](https://github.com/mobile-shell/mosh/issues/122){:target=&quot;_blank&quot;} de varios años donde los desarrolladores comentan que está a modo de referencia pero que no tienen ninguna intención de implementarlo. ¿Entonces no hay solución? Si, `tmux`.

# ¿Qué es tmux?

`tmux` es una herramienta que permite tener varias terminales abiertas (o ventanas) para que sean accedidas y controladas desde un solo terminal como haríamos con `screen`.  

Debes instalar `tmux` en el equipo donde deseamos iniciar sesión y una vez instalado basta con ejecutar esto desde el cliente `mosh` (el iPad Pro en mi caso):

```
mosh danuntless -- tmux new  -s terminal-1
```

De esta forma creamos una sessión nueva cuyo nombre es **terminal-1**. Luego para acceder a esta sesión posteriormente debemos ejecutar lo siguiente:

`mosh danuntless -- tmux a  -t terminal-1`

## Activar scrolling  en tmux

En la estación de trabajo remota se debe configurar `mosh` para tener el scrroling con `tmux`, esto se consigue editando el archivo `~/.tmux.conf` con este contenido:

```
new-session
set -g history-limit 30000
set -g mouse on
```

## Blink + ssh  + mosh + tmux ... eh?

&quot;Espera un momento... **Blink + ssh + mosh +  tmux**, no es medio complicado todo? No es mejor usar `ssh` con `screen`? &quot;. Sí, es una alternativa pero con `ssh` no te reconectarás automáticamente y tendrás que loguearte nuevamente si por ejemplo cierras el iPad, si tu dirección IP cambia por algún motivo (por ejemplo cambias de WiFI a línea telefónica) o si la sesión `ssh` expira.

Reconozco que hay una curva de aprendizaje con `tmux` pero una vez superada te va a encantar y te preguntarás por qué no usaste antes `mosh` y `tmux`

## Más sobre tmux

Si quieres aprender a usar `tmux` te dejo una [cheat sheet](https://tmuxcheatsheet.com){:target=&quot;_blank&quot;} con los comandos que puedes usar. En particular encontré muy útil la división en paneles y el uso del zoom entre ellos, pero debo admitir que copiar texto entre paneles es algo complicado en el iPad y a veces prefiero usar `vim` para esto, pero seguro ya le encontraré la vuelta.

# Palabras finales

Si bien acá comento la experiencia con el iPad Pro, todo esto se puede replicar en un iPad Air e incluso usar `mosh` y `tmux` desde otras estaciones de trabajo con Linux o Windows.

# Referencias

* [Run ANY OS on iPad or iPhone! - YouTube](https://youtu.be/LrLDKYFyLMM){:target=&quot;_blank&quot;}
* [Using the iPad Pro as my development machine](https://arslan.io/2019/01/07/using-the-ipad-pro-as-my-development-machine/){:target=&quot;_blank&quot;}
* [Blink Shell](https://blink.sh){:target=&quot;_blank&quot;}
* [Mosh](https://blink.sh){:target=&quot;_blank&quot;}
* [Tmux cheat sheet](https://tmuxcheatsheet.com)
* [mosh prevents the use of scrollback](https://github.com/mobile-shell/mosh/issues/122){:target=&quot;_blank&quot;}</content><author><name>Luis M. Gallardo D.</name></author></entry><entry><title type="html"></title><link href="https://lgallardo.com/es/_i18n/es/2021-06-15-helm3-local-repo.md/" rel="alternate" type="text/html" title="" /><published>2025-06-09T07:19:12-05:00</published><updated>2025-06-09T07:19:12-05:00</updated><id>https://lgallardo.com/es/_i18n/es/2021-06-15-helm3-local-repo.md</id><content type="html" xml:base="https://lgallardo.com/es/_i18n/es/2021-06-15-helm3-local-repo.md/">![Repositorio local para Helm 3](/assets/images/helm.jpg){:style=&quot;display:block; margin-left:auto; margin-right:auto&quot;}
En Helm 3, el soporte del comando **helm serve** se eliminó debido a algunos problemas de diseño, por lo tanto, si necesita una herramienta similar debes instalar el complemento **helm servecm**, que usa **ChartMuseum** para publicar los charts en tu medio de almacenamiento local (también se admiten otros medios de almacenamientos, como los buckets de S3).

En esta artículo aprenderá cómo instalar y publicar un repositorio local en Helm 3.



1. Instala **ChartMuseum**&lt;br/&gt;
   En primer lugar, debes instalar **ChartMuseum**. En la página del proyecto encontrará diferentes formas de instalarlo, pero yo lo instalo como una aplicación Go de la siguiente manera:
   ```bash
   GO111MODULE=&quot;on&quot; go get github.com/helm/chartmuseum@v0.13.1
   ```
   
2. Instala  **helm servecm plugin**&lt;br/&gt;

   &lt;br/&gt;Entonces necesitas instalar **servecm** como un complemento de helm:&lt;br/&gt;&lt;br/&gt;

   ```bash
   helm plugin install https://github.com/jdolitsky/helm-servecm
   ```

3. Instala **helm push plugin**&lt;br/&gt;
   Para alojar tus charts, usarás **ChartMuseum** y **helm servecm** pluing, pero aún tendrás que publicarlos en **ChartMuseum**. Puedes hacerlo manualmente o usar otro complemento llamado **helm push** que lo hace por ti:&lt;br/&gt;&lt;br/&gt;

   ```bash
   helm plugin install https://github.com/chartmuseum/helm-push.git
   ```

4. Agrega el repo local repo en helm:&lt;br/&gt;&lt;br/&gt;

   ```
   helm repo add local http://127.0.0.1:8879/charts
   ```

5. Corre **helm servecm plugin**:

   &lt;br/&gt;El siguiente paso es correr el plugin **helm servecm**:&lt;br/&gt;&lt;br/&gt;

   ```bash
   helm servecm --port=8879 --storage local --storage-local-rootdir ./local --context-path=/charts 
   ```

   Ahora puedes publicar tus charts en  http://127.0.0.1:8879/charts

6. Publica tu chart en tu repositorio local:

   ```bash
   helm push your-chart local
   ```

En este punto ya podrás utilizar tus charts locales en tu clúster ejecutando:

```bash
helm install  your-chart
```

## Referencias
* [Removal of helm serve](https://helm.sh/docs/faq/#removal-of-helm-serve){:target=&quot;_blank&quot;}
* [helm servecm plugin](https://github.com/jdolitsky/helm-servecm){:target=&quot;_blank&quot;}
* [ChartMuseum](https://github.com/helm/chartmuseum){:target=&quot;_blank&quot;}
* [helm push plugin](https://github.com/chartmuseum/helm-push){:target=&quot;_blank&quot;}</content><author><name>Luis M. Gallardo D.</name></author></entry><entry><title type="html"></title><link href="https://lgallardo.com/es/_i18n/es/2021-04-15-terraform-module-for-aws-ecr.md/" rel="alternate" type="text/html" title="" /><published>2025-06-09T07:19:12-05:00</published><updated>2025-06-09T07:19:12-05:00</updated><id>https://lgallardo.com/es/_i18n/es/2021-04-15-terraform-module-for-aws-ecr.md</id><content type="html" xml:base="https://lgallardo.com/es/_i18n/es/2021-04-15-terraform-module-for-aws-ecr.md/">&lt;center&gt;&lt;img src=&quot;/images/terraform-aws-ecr.jpg&quot; alt=&quot;Terraform&quot; /&gt;&lt;/center&gt;&lt;br/&gt;
Les comparto acá otro módulo de Terraform que publiqué como código Open Source, el cual permite crear registries en AWS ECR.


Puedes ver el módulo **terraform-aws-ecr** en el [Terraform Registry](https://registry.terraform.io/modules/lgallard/ecr/aws){:target=&quot;_blank&quot;} o clonarlo desde [Github](https://github.com/lgallard/terraform-aws-ecr.git){:target=&quot;_blank&quot;}.

Si quieres echar un vistazo al módulo, también dejé el archivo README en esta publicación:

![Terraform](https://lgallardo.com/images/terraform.jpg){:target=&quot;_blank&quot;}

# terraform-aws-ecr
Terraform module to create [AWS ECR](https://aws.amazon.com/ecr/){:target=&quot;_blank&quot;} (Elastic Container Registry) which is a fully-managed Docker container registry.

## Usage
You can use this module to create an ECR registry using few parameters (simple example) or define in detail every aspect of the registry (complete example).

Check the [examples](https://github.com/lgallard/terraform-aws-ecr/tree/master/examples){:target=&quot;_blank&quot;} for the  **simple** and the **complete** snippets.

### Simple example
This example creates an ECR registry using few parameters

```
module &quot;ecr&quot; {

  source = &quot;lgallard/ecr/aws&quot;

  name         = &quot;ecr-repo-dev&quot;

  # Tags
  tags = {
    Owner       = &quot;DevOps team&quot;
    Environment = &quot;dev&quot;
    Terraform   = true
  }

}
```

### Complete example
In this example the register is defined in detailed.

```
module &quot;ecr&quot; {

  source = &quot;lgallard/ecr/aws&quot;

  name                 = &quot;ecr-repo-dev&quot;
  scan_on_push         = true
  timeouts_delete      = &quot;60m&quot;
  image_tag_mutability = &quot;MUTABLE&quot;


  # Note that currently only one policy may be applied to a repository.
  policy = &lt;&lt;EOF
{
    &quot;Version&quot;: &quot;2008-10-17&quot;,
    &quot;Statement&quot;: [
        {
            &quot;Sid&quot;: &quot;repo policy&quot;,
            &quot;Effect&quot;: &quot;Allow&quot;,
            &quot;Principal&quot;: &quot;*&quot;,
            &quot;Action&quot;: [
                &quot;ecr:GetDownloadUrlForLayer&quot;,
                &quot;ecr:BatchGetImage&quot;,
                &quot;ecr:BatchCheckLayerAvailability&quot;,
                &quot;ecr:PutImage&quot;,
                &quot;ecr:InitiateLayerUpload&quot;,
                &quot;ecr:UploadLayerPart&quot;,
                &quot;ecr:CompleteLayerUpload&quot;,
                &quot;ecr:DescribeRepositories&quot;,
                &quot;ecr:GetRepositoryPolicy&quot;,
                &quot;ecr:ListImages&quot;,
                &quot;ecr:DeleteRepository&quot;,
                &quot;ecr:BatchDeleteImage&quot;,
                &quot;ecr:SetRepositoryPolicy&quot;,
                &quot;ecr:DeleteRepositoryPolicy&quot;
            ]
        }
    ]
}
EOF

  # Only one lifecycle policy can be used per repository.
  # To apply multiple rules, combined them in one policy JSON.
  lifecycle_policy = &lt;&lt;EOF
{
    &quot;rules&quot;: [
        {
            &quot;rulePriority&quot;: 1,
            &quot;description&quot;: &quot;Expire untagged images older than 14 days&quot;,
            &quot;selection&quot;: {
                &quot;tagStatus&quot;: &quot;untagged&quot;,
                &quot;countType&quot;: &quot;sinceImagePushed&quot;,
                &quot;countUnit&quot;: &quot;days&quot;,
                &quot;countNumber&quot;: 14
            },
            &quot;action&quot;: {
                &quot;type&quot;: &quot;expire&quot;
            }
        },
        {
            &quot;rulePriority&quot;: 2,
            &quot;description&quot;: &quot;Keep last 30 dev images&quot;,
            &quot;selection&quot;: {
                &quot;tagStatus&quot;: &quot;tagged&quot;,
                &quot;tagPrefixList&quot;: [&quot;dev&quot;],
                &quot;countType&quot;: &quot;imageCountMoreThan&quot;,
                &quot;countNumber&quot;: 30
            },
            &quot;action&quot;: {
                &quot;type&quot;: &quot;expire&quot;
            }
        }
    ]
}
EOF

  # Tags
  tags = {
    Owner       = &quot;DevOps team&quot;
    Environment = &quot;dev&quot;
    Terraform   = true
  }

}

```
## Providers

| Name | Version |
|------|---------|
| aws | n/a |

## Inputs

| Name | Description | Type | Default | Required |
|------|-------------|------|---------|:--------:|
| encryption\_type | The encryption type to use for the repository. Valid values are `AES256` or `KMS` | `string` | `&quot;AES256&quot;` | no |
| image\_scanning\_configuration | Configuration block that defines image scanning configuration for the repository. By default, image scanning must be manually triggered. See the ECR User Guide for more information about image scanning. | `map` | `{}` | no |
| image\_tag\_mutability | The tag mutability setting for the repository. Must be one of: `MUTABLE` or `IMMUTABLE`. | `string` | `&quot;MUTABLE&quot;` | no |
| kms\_key | The ARN of the KMS key to use when encryption\_type is `KMS`. If not specified when encryption\_type is `KMS`, uses a new KMS key. Otherwise, uses the default AWS managed key for ECR. | `string` | n/a | no |
| lifecycle\_policy | Manages the ECR repository lifecycle policy | `string` | n/a | yes |
| name | Name of the repository. | `string` | n/a | yes |
| policy | Manages the ECR repository policy | `string` | n/a | yes |
| scan\_on\_push | Indicates whether images are scanned after being pushed to the repository (true) or not scanned (false). | `bool` | `true` | no |
| tags | A mapping of tags to assign to the resource. | `map(string)` | `{}` | no |
| timeouts | Timeouts map. | `map` | `{}` | no |
| timeouts\_delete | How long to wait for a repository to be deleted. | `string` | n/a | no |

## Outputs

| Name | Description |
|------|-------------|
| arn | Full ARN of the repository |
| name | The name of the repository. |
| registry\_id | The registry ID where the repository was created. |
| repository\_url | The URL of the repository (in the form `aws_account_id.dkr.ecr.region.amazonaws.com/repositoryName`) |

## References

* [terraform-aws-ecr module at Github](https://github.com/lgallard/terraform-aws-ecr.git){:target=&quot;_blank&quot;}
* [terraform-aws-ecr module at Terraform Registry](https://registry.terraform.io/modules/lgallard/ecr/aws){:target=&quot;_blank&quot;}</content><author><name>Luis M. Gallardo D.</name></author></entry></feed>